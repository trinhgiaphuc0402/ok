```mermaid
graph TB

%% User Input
U[ğŸ‘¤ User\nCÃ¢u há»i vá» thuá»‘c] --> Q{ğŸ“ Query\nTÃ´i bá»‹ Ä‘au Ä‘áº§u,\ncÃ³ thuá»‘c gÃ¬ khÃ´ng?}

%% RAG Process Box
subgraph RAG ["ğŸ¤– RAG Chatbot Service"]
    direction TB

    %% Indexing Section
    subgraph IDX ["ğŸ“š Indexing"]
        direction TB
        DOC[ğŸ“„ Documents\nMySQL Database\nMedicine Data]
        CHUNK[ğŸ”¤ Chunk/Vectors\nSentenceTransformer\nparaphrase-multilingual-MiniLM-L12-v2]
        EMB[ğŸ§  Embeddings\nVector Cache\n384-dimensional]
        DOC --> CHUNK --> EMB
    end

    %% Retrieval Section
    RET[ğŸ” Retrieval\nHybrid Search:\nExact Match + Semantic Search\nCosine Similarity â‰¥ 0.3]

    %% Relevant Documents
    REL[ğŸ“‹ Relevant Documents\nTop 5 thuá»‘c liÃªn quan:\nAspirin 0.85\nParacetamol 0.72\nIbuprofen 0.68]

    EMB --> RET
    RET --> REL
end

%% LLM Generation
Q --> RAG
REL --> COMB[ğŸ”„ Combine Context\nand Prompts\nFormat thÃ´ng tin thuá»‘c\n+ System prompt\nDÆ°á»£c sÄ© chuyÃªn nghiá»‡p]

COMB --> LLM[ğŸ§  LLM\nOpenAI GPT-4\nTemperature: 0.7\nMax tokens: 500]

%% Output
LLM --> ANS[ğŸ“¤ Answer\nGiá»›i thiá»‡u vÃ  cÃ´ng dá»¥ng: Aspirin lÃ  thuá»‘c giáº£m Ä‘au...\nCÃ¡ch sá»­ dá»¥ng: Uá»‘ng 1 viÃªn má»—i 8 tiáº¿ng...\nGiÃ¡ cáº£: 25,000 VND\nLÆ°u Ã½: KhÃ´ng dÃ¹ng cho tráº» dÆ°á»›i 12 tuá»•i]

%% Response with RAG
subgraph RESP ["âœ… with RAG"]
    FINAL[ğŸ“Š Response JSON\nAI response + Medicine list\nSimilarity scores + Metadata]
end

ANS --> FINAL
FINAL --> OUT[ğŸ“± Output\nReact Frontend\nHiá»ƒn thá»‹ tÆ° váº¥n + danh sÃ¡ch thuá»‘c]
```
