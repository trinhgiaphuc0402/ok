```mermaid
graph TB

%% User Input
U[ğŸ‘¤ User<br/>Query:<br/>TÃ´i bá»‹ Ä‘au Ä‘áº§u,<br/>cÃ³ thuá»‘c gÃ¬ khÃ´ng?] --> Q

%% RAG Process Box
subgraph RAG ["ğŸ¤– RAG Chatbot Service"]
    direction TB

    %% Indexing Section
    subgraph IDX ["ğŸ“š Indexing"]
        direction TB
        DOC1[ğŸ“„ Documents<br/>Multidatabase Medicine Data]
        DOC2[ğŸ“„ Documents<br/>MySQL Database Medicine Data]
        EMB[ğŸ§  Embeddings<br/>Vector Cache (384-dimensional)]
        MODEL[ğŸ”¤ SentenceTransformer<br/>paraphrase-multilingual-MiniLM-L12-v2]
        DOC1 --> EMB
        DOC2 --> EMB
        MODEL --> EMB
    end

    %% Retrieval Section
    RET[ğŸ” Retrieval<br/>Hybrid Search:<br/>Exact Match + Semantic Search<br/>Cosine Similarity â‰¥ 0.3]

    %% Relevant Documents
    REL[ğŸ“‹ Relevant Documents<br/>Top 5 thuá»‘c liÃªn quan:<br/>Aspirin - 0.85<br/>Paracetamol - 0.72<br/>Ibuprofen - 0.88]

    EMB --> RET
    RET --> REL
end

%% Combine context + prompts
REL --> COMB[ğŸ”„ Combine Context & Prompts<br/>Format thÃ´ng tin thuá»‘c<br/>+ System prompt<br/>DÆ°á»£c sÄ© chuyÃªn nghiá»‡p]

%% LLM
COMB --> LLM[ğŸ§  LLM<br/>OpenAI GPT-4<br/>Temperature: 0.7<br/>Max tokens: 300]

%% Output Answer
LLM --> ANS[ğŸ“¤ Answer<br/>- Giá»›i thiá»‡u & cÃ´ng dá»¥ng: Aspirin lÃ  thuá»‘c giáº£m Ä‘au, háº¡ sá»‘tâ€¦<br/>- CÃ¡ch sá»­ dá»¥ng: Uá»‘ng 1 viÃªn má»—i 8 tiáº¿ng<br/>- GiÃ¡ cáº£: 25,000 VND<br/>- LÆ°u Ã½: KhÃ´ng dÃ¹ng cho tráº» dÆ°á»›i 12 tuá»•i]

%% Response with RAG
subgraph RESP ["âœ… with RAG"]
    FINAL[ğŸ“Š Response JSON<br/>AI response + Medicine list<br/>Similarity scores + Metadata]
end

ANS --> FINAL
FINAL --> OUT[ğŸ“± Output<br/>React Frontend<br/>Hiá»ƒn thá»‹ tÆ° váº¥n + danh sÃ¡ch thuá»‘c]
